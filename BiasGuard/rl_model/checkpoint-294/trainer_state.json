{
  "best_global_step": 294,
  "best_metric": 0.4363822937011719,
  "best_model_checkpoint": "rl_model/checkpoint-294",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 294,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10256410256410256,
      "grad_norm": 0.6629528403282166,
      "learning_rate": 1.8e-05,
      "logits/chosen": -1.5956897735595703,
      "logits/rejected": -1.586548089981079,
      "logps/chosen": -195.7620849609375,
      "logps/rejected": -194.97958374023438,
      "loss": 0.6926,
      "rewards/accuracies": 0.22499999403953552,
      "rewards/chosen": 0.0023248668294399977,
      "rewards/margins": 0.0012422942090779543,
      "rewards/rejected": 0.0010825727367773652,
      "step": 10
    },
    {
      "epoch": 0.20512820512820512,
      "grad_norm": 1.3957056999206543,
      "learning_rate": 3.8e-05,
      "logits/chosen": -1.625777244567871,
      "logits/rejected": -1.6197316646575928,
      "logps/chosen": -180.96524047851562,
      "logps/rejected": -186.3340606689453,
      "loss": 0.6877,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.0026805116795003414,
      "rewards/margins": 0.011168976314365864,
      "rewards/rejected": -0.008488464169204235,
      "step": 20
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 0.840695321559906,
      "learning_rate": 5.8e-05,
      "logits/chosen": -1.6092758178710938,
      "logits/rejected": -1.5903030633926392,
      "logps/chosen": -176.60804748535156,
      "logps/rejected": -190.9437255859375,
      "loss": 0.6524,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.06297314167022705,
      "rewards/margins": 0.09277866780757904,
      "rewards/rejected": -0.02980552241206169,
      "step": 30
    },
    {
      "epoch": 0.41025641025641024,
      "grad_norm": 1.4734665155410767,
      "learning_rate": 7.800000000000001e-05,
      "logits/chosen": -1.5960285663604736,
      "logits/rejected": -1.5709730386734009,
      "logps/chosen": -219.07052612304688,
      "logps/rejected": -186.02215576171875,
      "loss": 0.5776,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.25214776396751404,
      "rewards/margins": 0.44583192467689514,
      "rewards/rejected": -0.19368413090705872,
      "step": 40
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.9331775903701782,
      "learning_rate": 9.8e-05,
      "logits/chosen": -1.53315007686615,
      "logits/rejected": -1.5567350387573242,
      "logps/chosen": -190.14671325683594,
      "logps/rejected": -224.60598754882812,
      "loss": 0.5717,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.15118101239204407,
      "rewards/margins": 0.6779278516769409,
      "rewards/rejected": -0.8291088342666626,
      "step": 50
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 2.1888556480407715,
      "learning_rate": 0.000118,
      "logits/chosen": -1.5643575191497803,
      "logits/rejected": -1.5486983060836792,
      "logps/chosen": -206.00009155273438,
      "logps/rejected": -219.1212158203125,
      "loss": 0.7148,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.8608959913253784,
      "rewards/margins": 0.9176527261734009,
      "rewards/rejected": -1.7785488367080688,
      "step": 60
    },
    {
      "epoch": 0.717948717948718,
      "grad_norm": 2.525399684906006,
      "learning_rate": 0.000138,
      "logits/chosen": -1.58596932888031,
      "logits/rejected": -1.5437686443328857,
      "logps/chosen": -218.6010284423828,
      "logps/rejected": -210.42056274414062,
      "loss": 0.5682,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -1.6989943981170654,
      "rewards/margins": 0.8380716443061829,
      "rewards/rejected": -2.5370659828186035,
      "step": 70
    },
    {
      "epoch": 0.8205128205128205,
      "grad_norm": 2.823270082473755,
      "learning_rate": 0.00015800000000000002,
      "logits/chosen": -1.5020660161972046,
      "logits/rejected": -1.512882113456726,
      "logps/chosen": -194.56411743164062,
      "logps/rejected": -229.8075408935547,
      "loss": 0.4275,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.4111546277999878,
      "rewards/margins": 1.9665582180023193,
      "rewards/rejected": -3.3777129650115967,
      "step": 80
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 6.758650779724121,
      "learning_rate": 0.00017800000000000002,
      "logits/chosen": -1.414530873298645,
      "logits/rejected": -1.3914964199066162,
      "logps/chosen": -225.1163330078125,
      "logps/rejected": -222.8415985107422,
      "loss": 0.8737,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -1.6695458889007568,
      "rewards/margins": 0.9211421012878418,
      "rewards/rejected": -2.5906879901885986,
      "step": 90
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": -1.6240772008895874,
      "eval_logits/rejected": -1.5996108055114746,
      "eval_logps/chosen": -171.64053344726562,
      "eval_logps/rejected": -184.62808227539062,
      "eval_loss": 0.6909180283546448,
      "eval_rewards/accuracies": 0.47727271914482117,
      "eval_rewards/chosen": 1.0999456644058228,
      "eval_rewards/margins": 1.2434557676315308,
      "eval_rewards/rejected": -0.14350999891757965,
      "eval_runtime": 13.6448,
      "eval_samples_per_second": 3.225,
      "eval_steps_per_second": 3.225,
      "step": 98
    },
    {
      "epoch": 1.0205128205128204,
      "grad_norm": 1.3611756563186646,
      "learning_rate": 0.00019800000000000002,
      "logits/chosen": -1.603360652923584,
      "logits/rejected": -1.570755958557129,
      "logps/chosen": -182.38836669921875,
      "logps/rejected": -183.34344482421875,
      "loss": 0.4694,
      "rewards/accuracies": 0.5526315569877625,
      "rewards/chosen": 1.0911369323730469,
      "rewards/margins": 1.3352617025375366,
      "rewards/rejected": -0.24412478506565094,
      "step": 100
    },
    {
      "epoch": 1.123076923076923,
      "grad_norm": 3.5214157104492188,
      "learning_rate": 0.0001993661971830986,
      "logits/chosen": -1.5282394886016846,
      "logits/rejected": -1.5069220066070557,
      "logps/chosen": -184.0902557373047,
      "logps/rejected": -188.2932586669922,
      "loss": 0.4934,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.30878689885139465,
      "rewards/margins": 1.5934638977050781,
      "rewards/rejected": -1.2846769094467163,
      "step": 110
    },
    {
      "epoch": 1.2256410256410257,
      "grad_norm": 0.21852396428585052,
      "learning_rate": 0.00019866197183098593,
      "logits/chosen": -1.4834837913513184,
      "logits/rejected": -1.496651530265808,
      "logps/chosen": -195.85061645507812,
      "logps/rejected": -233.7659454345703,
      "loss": 0.6079,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.200925350189209,
      "rewards/margins": 2.0527749061584473,
      "rewards/rejected": -4.253700256347656,
      "step": 120
    },
    {
      "epoch": 1.3282051282051281,
      "grad_norm": 0.8551172614097595,
      "learning_rate": 0.00019795774647887325,
      "logits/chosen": -1.661989450454712,
      "logits/rejected": -1.7107183933258057,
      "logps/chosen": -175.71131896972656,
      "logps/rejected": -204.5130157470703,
      "loss": 0.4414,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.20365357398986816,
      "rewards/margins": 1.8892152309417725,
      "rewards/rejected": -2.0928688049316406,
      "step": 130
    },
    {
      "epoch": 1.4307692307692308,
      "grad_norm": 1.6192723512649536,
      "learning_rate": 0.00019725352112676058,
      "logits/chosen": -1.6068016290664673,
      "logits/rejected": -1.5974071025848389,
      "logps/chosen": -183.51356506347656,
      "logps/rejected": -230.39462280273438,
      "loss": 0.4794,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.4403422772884369,
      "rewards/margins": 2.2450356483459473,
      "rewards/rejected": -2.685377597808838,
      "step": 140
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 7.270750522613525,
      "learning_rate": 0.0001965492957746479,
      "logits/chosen": -1.4703510999679565,
      "logits/rejected": -1.4252071380615234,
      "logps/chosen": -202.9014892578125,
      "logps/rejected": -206.764892578125,
      "loss": 0.4667,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.1347572803497314,
      "rewards/margins": 2.047628879547119,
      "rewards/rejected": -3.1823863983154297,
      "step": 150
    },
    {
      "epoch": 1.6358974358974359,
      "grad_norm": 9.84688663482666,
      "learning_rate": 0.00019584507042253523,
      "logits/chosen": -1.3122246265411377,
      "logits/rejected": -1.3254978656768799,
      "logps/chosen": -213.50448608398438,
      "logps/rejected": -237.14151000976562,
      "loss": 0.734,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -2.525613307952881,
      "rewards/margins": 2.0574727058410645,
      "rewards/rejected": -4.583085536956787,
      "step": 160
    },
    {
      "epoch": 1.7384615384615385,
      "grad_norm": 10.965143203735352,
      "learning_rate": 0.00019514084507042255,
      "logits/chosen": -1.3046907186508179,
      "logits/rejected": -1.3210196495056152,
      "logps/chosen": -270.84967041015625,
      "logps/rejected": -227.3476104736328,
      "loss": 0.4442,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -2.458444118499756,
      "rewards/margins": 2.3355884552001953,
      "rewards/rejected": -4.794033050537109,
      "step": 170
    },
    {
      "epoch": 1.8410256410256411,
      "grad_norm": 2.6213173866271973,
      "learning_rate": 0.00019443661971830985,
      "logits/chosen": -1.4098933935165405,
      "logits/rejected": -1.3679946660995483,
      "logps/chosen": -240.1447296142578,
      "logps/rejected": -255.740966796875,
      "loss": 0.5157,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.5061638355255127,
      "rewards/margins": 3.2333977222442627,
      "rewards/rejected": -4.739561557769775,
      "step": 180
    },
    {
      "epoch": 1.9435897435897436,
      "grad_norm": 8.106451988220215,
      "learning_rate": 0.00019373239436619718,
      "logits/chosen": -1.6516377925872803,
      "logits/rejected": -1.591626763343811,
      "logps/chosen": -209.98696899414062,
      "logps/rejected": -264.90264892578125,
      "loss": 0.6481,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -1.9933515787124634,
      "rewards/margins": 1.8240032196044922,
      "rewards/rejected": -3.817354917526245,
      "step": 190
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": -1.7801381349563599,
      "eval_logits/rejected": -1.7450450658798218,
      "eval_logps/chosen": -187.07737731933594,
      "eval_logps/rejected": -206.30087280273438,
      "eval_loss": 0.6506748795509338,
      "eval_rewards/accuracies": 0.5454545617103577,
      "eval_rewards/chosen": -0.44373905658721924,
      "eval_rewards/margins": 1.8670501708984375,
      "eval_rewards/rejected": -2.3107893466949463,
      "eval_runtime": 13.6454,
      "eval_samples_per_second": 3.225,
      "eval_steps_per_second": 3.225,
      "step": 196
    },
    {
      "epoch": 2.041025641025641,
      "grad_norm": 10.62475872039795,
      "learning_rate": 0.0001930281690140845,
      "logits/chosen": -1.8416800498962402,
      "logits/rejected": -1.7054343223571777,
      "logps/chosen": -195.02609252929688,
      "logps/rejected": -230.4805450439453,
      "loss": 0.4568,
      "rewards/accuracies": 0.5789473652839661,
      "rewards/chosen": 0.8716533780097961,
      "rewards/margins": 2.4400031566619873,
      "rewards/rejected": -1.568350076675415,
      "step": 200
    },
    {
      "epoch": 2.1435897435897435,
      "grad_norm": 1.076327919960022,
      "learning_rate": 0.00019232394366197183,
      "logits/chosen": -1.6780436038970947,
      "logits/rejected": -1.659035325050354,
      "logps/chosen": -183.9696502685547,
      "logps/rejected": -200.32308959960938,
      "loss": 0.3774,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.7486680746078491,
      "rewards/margins": 2.6781439781188965,
      "rewards/rejected": -1.9294761419296265,
      "step": 210
    },
    {
      "epoch": 2.246153846153846,
      "grad_norm": 4.482228755950928,
      "learning_rate": 0.00019161971830985915,
      "logits/chosen": -1.581668496131897,
      "logits/rejected": -1.4985138177871704,
      "logps/chosen": -206.4053497314453,
      "logps/rejected": -252.42471313476562,
      "loss": 0.5398,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8109840154647827,
      "rewards/margins": 3.5766658782958984,
      "rewards/rejected": -4.387650489807129,
      "step": 220
    },
    {
      "epoch": 2.348717948717949,
      "grad_norm": 11.227755546569824,
      "learning_rate": 0.00019091549295774648,
      "logits/chosen": -1.514448881149292,
      "logits/rejected": -1.5476658344268799,
      "logps/chosen": -221.63504028320312,
      "logps/rejected": -244.5227508544922,
      "loss": 0.5879,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -2.7132580280303955,
      "rewards/margins": 3.2966697216033936,
      "rewards/rejected": -6.009928226470947,
      "step": 230
    },
    {
      "epoch": 2.4512820512820515,
      "grad_norm": 0.9251135587692261,
      "learning_rate": 0.0001902112676056338,
      "logits/chosen": -1.659857153892517,
      "logits/rejected": -1.6743379831314087,
      "logps/chosen": -194.00462341308594,
      "logps/rejected": -232.4637451171875,
      "loss": 0.6942,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -2.209815502166748,
      "rewards/margins": 1.5974094867706299,
      "rewards/rejected": -3.807224988937378,
      "step": 240
    },
    {
      "epoch": 2.5538461538461537,
      "grad_norm": 12.457027435302734,
      "learning_rate": 0.00018950704225352113,
      "logits/chosen": -1.6800320148468018,
      "logits/rejected": -1.6439645290374756,
      "logps/chosen": -221.98214721679688,
      "logps/rejected": -230.5657196044922,
      "loss": 0.5925,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -2.4519777297973633,
      "rewards/margins": 2.4828624725341797,
      "rewards/rejected": -4.934840202331543,
      "step": 250
    },
    {
      "epoch": 2.6564102564102563,
      "grad_norm": 8.649104118347168,
      "learning_rate": 0.00018880281690140846,
      "logits/chosen": -1.4532806873321533,
      "logits/rejected": -1.4715133905410767,
      "logps/chosen": -218.6353759765625,
      "logps/rejected": -234.67166137695312,
      "loss": 0.5181,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.7962190508842468,
      "rewards/margins": 2.758974552154541,
      "rewards/rejected": -3.5551934242248535,
      "step": 260
    },
    {
      "epoch": 2.758974358974359,
      "grad_norm": 30.851070404052734,
      "learning_rate": 0.00018809859154929578,
      "logits/chosen": -1.3611576557159424,
      "logits/rejected": -1.3784408569335938,
      "logps/chosen": -207.1536865234375,
      "logps/rejected": -267.51641845703125,
      "loss": 0.5305,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -3.374577283859253,
      "rewards/margins": 3.4373879432678223,
      "rewards/rejected": -6.8119659423828125,
      "step": 270
    },
    {
      "epoch": 2.8615384615384616,
      "grad_norm": 14.23299503326416,
      "learning_rate": 0.0001873943661971831,
      "logits/chosen": -1.4092941284179688,
      "logits/rejected": -1.4425476789474487,
      "logps/chosen": -238.4091796875,
      "logps/rejected": -235.0935821533203,
      "loss": 0.6349,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -2.7683920860290527,
      "rewards/margins": 2.8706860542297363,
      "rewards/rejected": -5.639077663421631,
      "step": 280
    },
    {
      "epoch": 2.9641025641025642,
      "grad_norm": 12.570211410522461,
      "learning_rate": 0.00018669014084507043,
      "logits/chosen": -1.6087722778320312,
      "logits/rejected": -1.674860954284668,
      "logps/chosen": -211.0310821533203,
      "logps/rejected": -235.30215454101562,
      "loss": 0.5177,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -1.9567296504974365,
      "rewards/margins": 2.41267728805542,
      "rewards/rejected": -4.3694071769714355,
      "step": 290
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": -1.7173947095870972,
      "eval_logits/rejected": -1.7164649963378906,
      "eval_logps/chosen": -224.22190856933594,
      "eval_logps/rejected": -248.64614868164062,
      "eval_loss": 0.4363822937011719,
      "eval_rewards/accuracies": 0.5454545617103577,
      "eval_rewards/chosen": -4.1581902503967285,
      "eval_rewards/margins": 2.38712477684021,
      "eval_rewards/rejected": -6.545314311981201,
      "eval_runtime": 13.6589,
      "eval_samples_per_second": 3.221,
      "eval_steps_per_second": 3.221,
      "step": 294
    }
  ],
  "logging_steps": 10,
  "max_steps": 2940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
