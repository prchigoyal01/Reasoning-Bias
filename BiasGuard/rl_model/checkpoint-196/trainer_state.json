{
  "best_global_step": 196,
  "best_metric": 0.5523583889007568,
  "best_model_checkpoint": "rl_model/checkpoint-196",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 196,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05128205128205128,
      "grad_norm": 0.3431780934333801,
      "learning_rate": 8.000000000000001e-06,
      "logits/chosen": 0.22710244357585907,
      "logits/rejected": 0.06299558281898499,
      "logps/chosen": -75.07015228271484,
      "logps/rejected": -78.22291564941406,
      "loss": 0.6919,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": 0.0010329054202884436,
      "rewards/margins": 0.0026315690483897924,
      "rewards/rejected": -0.0015986630460247397,
      "step": 5
    },
    {
      "epoch": 0.10256410256410256,
      "grad_norm": 0.6340786814689636,
      "learning_rate": 1.8e-05,
      "logits/chosen": 0.09705774486064911,
      "logits/rejected": 0.13925513625144958,
      "logps/chosen": -95.75894927978516,
      "logps/rejected": -96.59010314941406,
      "loss": 0.692,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007215575780719519,
      "rewards/margins": 0.0026292039547115564,
      "rewards/rejected": 0.004586372524499893,
      "step": 10
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.6277332305908203,
      "learning_rate": 2.8000000000000003e-05,
      "logits/chosen": -0.03949930891394615,
      "logits/rejected": 0.04190049320459366,
      "logps/chosen": -86.26441955566406,
      "logps/rejected": -84.90690612792969,
      "loss": 0.6934,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.007406272925436497,
      "rewards/margins": -0.0003144076035823673,
      "rewards/rejected": 0.007720680441707373,
      "step": 15
    },
    {
      "epoch": 0.20512820512820512,
      "grad_norm": 1.114098310470581,
      "learning_rate": 3.8e-05,
      "logits/chosen": 0.1517392098903656,
      "logits/rejected": -0.014909768477082253,
      "logps/chosen": -76.41310119628906,
      "logps/rejected": -82.65299224853516,
      "loss": 0.686,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": 0.04056430608034134,
      "rewards/margins": 0.014657172374427319,
      "rewards/rejected": 0.025907134637236595,
      "step": 20
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 3.4749608039855957,
      "learning_rate": 4.8e-05,
      "logits/chosen": 0.003338022856041789,
      "logits/rejected": 0.08472588658332825,
      "logps/chosen": -80.22904968261719,
      "logps/rejected": -90.61122131347656,
      "loss": 0.6744,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": 0.11055850982666016,
      "rewards/margins": 0.040470242500305176,
      "rewards/rejected": 0.07008825987577438,
      "step": 25
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 1.4791791439056396,
      "learning_rate": 5.8e-05,
      "logits/chosen": 0.1238059252500534,
      "logits/rejected": 0.11279506981372833,
      "logps/chosen": -71.29327392578125,
      "logps/rejected": -75.4096908569336,
      "loss": 0.6581,
      "rewards/accuracies": 0.3499999940395355,
      "rewards/chosen": 0.23899754881858826,
      "rewards/margins": 0.08231720328330994,
      "rewards/rejected": 0.1566803753376007,
      "step": 30
    },
    {
      "epoch": 0.358974358974359,
      "grad_norm": 0.6156356930732727,
      "learning_rate": 6.800000000000001e-05,
      "logits/chosen": 0.05397214740514755,
      "logits/rejected": 0.11467935144901276,
      "logps/chosen": -97.30545806884766,
      "logps/rejected": -73.40494537353516,
      "loss": 0.6078,
      "rewards/accuracies": 0.3499999940395355,
      "rewards/chosen": 0.3591698706150055,
      "rewards/margins": 0.22394832968711853,
      "rewards/rejected": 0.13522155582904816,
      "step": 35
    },
    {
      "epoch": 0.41025641025641024,
      "grad_norm": 1.4313610792160034,
      "learning_rate": 7.800000000000001e-05,
      "logits/chosen": 0.033314842730760574,
      "logits/rejected": 0.06031506508588791,
      "logps/chosen": -85.4217758178711,
      "logps/rejected": -83.4016342163086,
      "loss": 0.5528,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.2764814794063568,
      "rewards/margins": 0.5117354989051819,
      "rewards/rejected": -0.23525400459766388,
      "step": 40
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 3.2554221153259277,
      "learning_rate": 8.800000000000001e-05,
      "logits/chosen": 0.04235469549894333,
      "logits/rejected": 0.05635561794042587,
      "logps/chosen": -84.93267059326172,
      "logps/rejected": -111.8355712890625,
      "loss": 0.4988,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.22434715926647186,
      "rewards/margins": 0.7753282189369202,
      "rewards/rejected": -0.5509810447692871,
      "step": 45
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 1.0682212114334106,
      "learning_rate": 9.8e-05,
      "logits/chosen": 0.16799402236938477,
      "logits/rejected": 0.037031106650829315,
      "logps/chosen": -87.4523696899414,
      "logps/rejected": -109.17254638671875,
      "loss": 0.6445,
      "rewards/accuracies": 0.30000001192092896,
      "rewards/chosen": -1.2605220079421997,
      "rewards/margins": 0.2195485532283783,
      "rewards/rejected": -1.4800704717636108,
      "step": 50
    },
    {
      "epoch": 0.5641025641025641,
      "grad_norm": 4.52194881439209,
      "learning_rate": 0.00010800000000000001,
      "logits/chosen": 0.11564023792743683,
      "logits/rejected": 0.11379919201135635,
      "logps/chosen": -100.57771301269531,
      "logps/rejected": -103.319580078125,
      "loss": 0.7521,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -1.8140579462051392,
      "rewards/margins": 0.18756911158561707,
      "rewards/rejected": -2.001626968383789,
      "step": 55
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 1.3293572664260864,
      "learning_rate": 0.000118,
      "logits/chosen": 0.10011240094900131,
      "logits/rejected": 0.18934263288974762,
      "logps/chosen": -118.59305572509766,
      "logps/rejected": -133.96180725097656,
      "loss": 0.4773,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7424217462539673,
      "rewards/margins": 1.517316222190857,
      "rewards/rejected": -3.2597382068634033,
      "step": 60
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.2937428951263428,
      "learning_rate": 0.00012800000000000002,
      "logits/chosen": 0.061051953583955765,
      "logits/rejected": 0.11438290029764175,
      "logps/chosen": -114.11979675292969,
      "logps/rejected": -113.28892517089844,
      "loss": 0.4826,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.035506010055542,
      "rewards/margins": 1.0816415548324585,
      "rewards/rejected": -3.117147445678711,
      "step": 65
    },
    {
      "epoch": 0.717948717948718,
      "grad_norm": 4.658917427062988,
      "learning_rate": 0.000138,
      "logits/chosen": 0.16314047574996948,
      "logits/rejected": 0.23533904552459717,
      "logps/chosen": -117.16352844238281,
      "logps/rejected": -109.69573974609375,
      "loss": 0.5606,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -2.4919967651367188,
      "rewards/margins": 0.7279620170593262,
      "rewards/rejected": -3.219958543777466,
      "step": 70
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.12372952699661255,
      "learning_rate": 0.000148,
      "logits/chosen": 0.1328151524066925,
      "logits/rejected": 0.29371821880340576,
      "logps/chosen": -115.114990234375,
      "logps/rejected": -128.66384887695312,
      "loss": 0.3238,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.744117259979248,
      "rewards/margins": 1.8474667072296143,
      "rewards/rejected": -4.591583728790283,
      "step": 75
    },
    {
      "epoch": 0.8205128205128205,
      "grad_norm": 3.525651216506958,
      "learning_rate": 0.00015800000000000002,
      "logits/chosen": 0.2612753212451935,
      "logits/rejected": 0.13156664371490479,
      "logps/chosen": -105.10957336425781,
      "logps/rejected": -155.71481323242188,
      "loss": 0.4462,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -2.8496713638305664,
      "rewards/margins": 2.771328926086426,
      "rewards/rejected": -5.62100076675415,
      "step": 80
    },
    {
      "epoch": 0.8717948717948718,
      "grad_norm": 9.876294136047363,
      "learning_rate": 0.000168,
      "logits/chosen": 0.07739101350307465,
      "logits/rejected": 0.04801385849714279,
      "logps/chosen": -110.9880599975586,
      "logps/rejected": -115.79890441894531,
      "loss": 1.0969,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.5827724933624268,
      "rewards/margins": 0.4479178488254547,
      "rewards/rejected": -4.030690670013428,
      "step": 85
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 8.75143814086914,
      "learning_rate": 0.00017800000000000002,
      "logits/chosen": -0.08700859546661377,
      "logits/rejected": -0.05329049751162529,
      "logps/chosen": -141.49929809570312,
      "logps/rejected": -144.6269989013672,
      "loss": 0.842,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -3.338585376739502,
      "rewards/margins": 1.1640957593917847,
      "rewards/rejected": -4.502680778503418,
      "step": 90
    },
    {
      "epoch": 0.9743589743589743,
      "grad_norm": 4.222952365875244,
      "learning_rate": 0.000188,
      "logits/chosen": 0.03998248651623726,
      "logits/rejected": -0.0015439450507983565,
      "logps/chosen": -104.87491607666016,
      "logps/rejected": -111.42774963378906,
      "loss": 0.5041,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.7232599258422852,
      "rewards/margins": 1.5119426250457764,
      "rewards/rejected": -3.2352027893066406,
      "step": 95
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 0.1990964561700821,
      "eval_logits/rejected": 0.20846033096313477,
      "eval_logps/chosen": -106.42340850830078,
      "eval_logps/rejected": -113.92695617675781,
      "eval_loss": 0.6370985507965088,
      "eval_rewards/accuracies": 0.5,
      "eval_rewards/chosen": -2.3563477993011475,
      "eval_rewards/margins": 1.029755711555481,
      "eval_rewards/rejected": -3.386103630065918,
      "eval_runtime": 13.7754,
      "eval_samples_per_second": 3.194,
      "eval_steps_per_second": 3.194,
      "step": 98
    },
    {
      "epoch": 1.0205128205128204,
      "grad_norm": 4.729328632354736,
      "learning_rate": 0.00019800000000000002,
      "logits/chosen": 0.07110225409269333,
      "logits/rejected": 0.17720896005630493,
      "logps/chosen": -107.751220703125,
      "logps/rejected": -110.21987915039062,
      "loss": 0.4661,
      "rewards/accuracies": 0.5555555820465088,
      "rewards/chosen": -1.8783245086669922,
      "rewards/margins": 1.0451555252075195,
      "rewards/rejected": -2.92348051071167,
      "step": 100
    },
    {
      "epoch": 1.0717948717948718,
      "grad_norm": 12.505453109741211,
      "learning_rate": 0.00019166666666666667,
      "logits/chosen": -0.46021372079849243,
      "logits/rejected": -0.4886384904384613,
      "logps/chosen": -158.64540100097656,
      "logps/rejected": -169.81756591796875,
      "loss": 0.5005,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -8.203624725341797,
      "rewards/margins": 1.1606143712997437,
      "rewards/rejected": -9.364238739013672,
      "step": 105
    },
    {
      "epoch": 1.123076923076923,
      "grad_norm": 0.48849835991859436,
      "learning_rate": 0.00018125000000000001,
      "logits/chosen": -3.220458507537842,
      "logits/rejected": -3.224454164505005,
      "logps/chosen": -389.2066955566406,
      "logps/rejected": -236.5729217529297,
      "loss": 15.0385,
      "rewards/accuracies": 0.3499999940395355,
      "rewards/chosen": -30.3281307220459,
      "rewards/margins": -13.938769340515137,
      "rewards/rejected": -16.38936424255371,
      "step": 110
    },
    {
      "epoch": 1.1743589743589744,
      "grad_norm": 0.31633511185646057,
      "learning_rate": 0.00017083333333333333,
      "logits/chosen": -3.207630157470703,
      "logits/rejected": -3.227470874786377,
      "logps/chosen": -236.7169952392578,
      "logps/rejected": -398.9891662597656,
      "loss": 0.5486,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": -16.38845443725586,
      "rewards/margins": 14.655637741088867,
      "rewards/rejected": -31.04408836364746,
      "step": 115
    },
    {
      "epoch": 1.2256410256410257,
      "grad_norm": 1.0883451700210571,
      "learning_rate": 0.00016041666666666667,
      "logits/chosen": -3.3477492332458496,
      "logits/rejected": -3.3322205543518066,
      "logps/chosen": -222.3849334716797,
      "logps/rejected": -276.27288818359375,
      "loss": 0.6451,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -14.666238784790039,
      "rewards/margins": 4.929870128631592,
      "rewards/rejected": -19.59610939025879,
      "step": 120
    },
    {
      "epoch": 1.2769230769230768,
      "grad_norm": 234.5519256591797,
      "learning_rate": 0.00015000000000000001,
      "logits/chosen": -2.42301607131958,
      "logits/rejected": -2.4108264446258545,
      "logps/chosen": -216.4253387451172,
      "logps/rejected": -267.80523681640625,
      "loss": 0.573,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -14.178253173828125,
      "rewards/margins": 4.527698993682861,
      "rewards/rejected": -18.70595359802246,
      "step": 125
    },
    {
      "epoch": 1.3282051282051281,
      "grad_norm": 108.24101257324219,
      "learning_rate": 0.00013958333333333333,
      "logits/chosen": -2.249544143676758,
      "logits/rejected": -2.287551164627075,
      "logps/chosen": -224.01513671875,
      "logps/rejected": -254.4122772216797,
      "loss": 1.5892,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -14.828763961791992,
      "rewards/margins": 2.179227113723755,
      "rewards/rejected": -17.007991790771484,
      "step": 130
    },
    {
      "epoch": 1.3794871794871795,
      "grad_norm": 3.43774151802063,
      "learning_rate": 0.00012916666666666667,
      "logits/chosen": -0.8371438980102539,
      "logits/rejected": -0.7849196195602417,
      "logps/chosen": -167.88580322265625,
      "logps/rejected": -215.65921020507812,
      "loss": 0.6506,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -9.210063934326172,
      "rewards/margins": 1.982891321182251,
      "rewards/rejected": -11.192955017089844,
      "step": 135
    },
    {
      "epoch": 1.4307692307692308,
      "grad_norm": 16.643600463867188,
      "learning_rate": 0.00011875,
      "logits/chosen": -0.6008270978927612,
      "logits/rejected": -0.5227715373039246,
      "logps/chosen": -187.5392608642578,
      "logps/rejected": -183.8899383544922,
      "loss": 1.4418,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -9.959776878356934,
      "rewards/margins": 0.37917888164520264,
      "rewards/rejected": -10.338956832885742,
      "step": 140
    },
    {
      "epoch": 1.4820512820512821,
      "grad_norm": 46.35374450683594,
      "learning_rate": 0.00010833333333333333,
      "logits/chosen": -0.31741148233413696,
      "logits/rejected": -0.3166777789592743,
      "logps/chosen": -183.17494201660156,
      "logps/rejected": -161.670166015625,
      "loss": 1.5169,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -8.766242980957031,
      "rewards/margins": -0.23725438117980957,
      "rewards/rejected": -8.528987884521484,
      "step": 145
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 21.611366271972656,
      "learning_rate": 9.791666666666667e-05,
      "logits/chosen": 0.30083590745925903,
      "logits/rejected": 0.2907062768936157,
      "logps/chosen": -120.04730224609375,
      "logps/rejected": -121.4028091430664,
      "loss": 0.8113,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.9371466636657715,
      "rewards/margins": 0.39667513966560364,
      "rewards/rejected": -4.333821773529053,
      "step": 150
    },
    {
      "epoch": 1.5846153846153848,
      "grad_norm": 3.479459047317505,
      "learning_rate": 8.75e-05,
      "logits/chosen": 0.6358696222305298,
      "logits/rejected": 0.6943214535713196,
      "logps/chosen": -107.6714859008789,
      "logps/rejected": -111.7151107788086,
      "loss": 0.64,
      "rewards/accuracies": 0.3499999940395355,
      "rewards/chosen": -3.1686906814575195,
      "rewards/margins": 0.44963040947914124,
      "rewards/rejected": -3.618320941925049,
      "step": 155
    },
    {
      "epoch": 1.6358974358974359,
      "grad_norm": 3.686937093734741,
      "learning_rate": 7.708333333333334e-05,
      "logits/chosen": 0.5773473381996155,
      "logits/rejected": 0.6090632081031799,
      "logps/chosen": -118.23274230957031,
      "logps/rejected": -145.54188537597656,
      "loss": 0.6778,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -3.0828213691711426,
      "rewards/margins": 1.6831802129745483,
      "rewards/rejected": -4.766001224517822,
      "step": 160
    },
    {
      "epoch": 1.6871794871794872,
      "grad_norm": 29.991790771484375,
      "learning_rate": 6.666666666666667e-05,
      "logits/chosen": 0.3120307922363281,
      "logits/rejected": 0.45028573274612427,
      "logps/chosen": -149.88568115234375,
      "logps/rejected": -128.48251342773438,
      "loss": 0.6365,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -3.5120272636413574,
      "rewards/margins": 1.4339244365692139,
      "rewards/rejected": -4.945952415466309,
      "step": 165
    },
    {
      "epoch": 1.7384615384615385,
      "grad_norm": 0.8747749328613281,
      "learning_rate": 5.6250000000000005e-05,
      "logits/chosen": 0.37019914388656616,
      "logits/rejected": 0.35258740186691284,
      "logps/chosen": -131.55111694335938,
      "logps/rejected": -123.94932556152344,
      "loss": 0.4623,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -3.2279906272888184,
      "rewards/margins": 1.322003960609436,
      "rewards/rejected": -4.549994945526123,
      "step": 170
    },
    {
      "epoch": 1.7897435897435896,
      "grad_norm": 1.3014355897903442,
      "learning_rate": 4.5833333333333334e-05,
      "logits/chosen": 0.17793351411819458,
      "logits/rejected": 0.2102009505033493,
      "logps/chosen": -132.28675842285156,
      "logps/rejected": -148.16722106933594,
      "loss": 0.6228,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -3.7285752296447754,
      "rewards/margins": 1.5285184383392334,
      "rewards/rejected": -5.2570929527282715,
      "step": 175
    },
    {
      "epoch": 1.8410256410256411,
      "grad_norm": 1.227972149848938,
      "learning_rate": 3.541666666666667e-05,
      "logits/chosen": 0.19763806462287903,
      "logits/rejected": 0.32051771879196167,
      "logps/chosen": -133.5135498046875,
      "logps/rejected": -135.78903198242188,
      "loss": 0.5583,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.2764620780944824,
      "rewards/margins": 1.2968882322311401,
      "rewards/rejected": -4.573349952697754,
      "step": 180
    },
    {
      "epoch": 1.8923076923076922,
      "grad_norm": 0.8362093567848206,
      "learning_rate": 2.5e-05,
      "logits/chosen": 0.260935515165329,
      "logits/rejected": 0.3742266297340393,
      "logps/chosen": -134.05490112304688,
      "logps/rejected": -150.8032684326172,
      "loss": 0.7412,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -3.9569287300109863,
      "rewards/margins": 1.1893671751022339,
      "rewards/rejected": -5.146296501159668,
      "step": 185
    },
    {
      "epoch": 1.9435897435897436,
      "grad_norm": 2.606712579727173,
      "learning_rate": 1.4583333333333335e-05,
      "logits/chosen": 0.341007798910141,
      "logits/rejected": 0.2460237294435501,
      "logps/chosen": -121.3583984375,
      "logps/rejected": -174.050048828125,
      "loss": 0.3913,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -4.084878444671631,
      "rewards/margins": 2.2387661933898926,
      "rewards/rejected": -6.323644638061523,
      "step": 190
    },
    {
      "epoch": 1.994871794871795,
      "grad_norm": 0.14903391897678375,
      "learning_rate": 4.166666666666667e-06,
      "logits/chosen": 0.43166956305503845,
      "logits/rejected": 0.36978045105934143,
      "logps/chosen": -114.45130920410156,
      "logps/rejected": -148.1586151123047,
      "loss": 0.4499,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.230351686477661,
      "rewards/margins": 2.264613389968872,
      "rewards/rejected": -5.494965553283691,
      "step": 195
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 0.3565675616264343,
      "eval_logits/rejected": 0.36963358521461487,
      "eval_logps/chosen": -121.21118927001953,
      "eval_logps/rejected": -131.20977783203125,
      "eval_loss": 0.5523583889007568,
      "eval_rewards/accuracies": 0.5227272510528564,
      "eval_rewards/chosen": -3.835127830505371,
      "eval_rewards/margins": 1.279258370399475,
      "eval_rewards/rejected": -5.114386558532715,
      "eval_runtime": 15.0309,
      "eval_samples_per_second": 2.927,
      "eval_steps_per_second": 2.927,
      "step": 196
    }
  ],
  "logging_steps": 5,
  "max_steps": 196,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
