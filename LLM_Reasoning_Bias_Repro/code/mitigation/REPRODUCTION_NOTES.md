# Bias Mitigation Pipeline - Implementation Overview

## Architecture

The mitigation pipeline implements two complementary bias reduction methods for reasoning-based LLMs, operating on chain-of-thought (CoT) reasoning generated by DeepSeek-R1-Distill-Qwen-14B on the BBQ sexual orientation dataset.

### Method 1: ADBP (Answer-Driven Bias Probing)

**How it mitigates bias**: Detects and corrects reasoning instability caused by biased intermediate steps.

ADBP treats bias as a reasoning stability problem. When biased stereotypes influence reasoning, they often cause answer fluctuations as more context is added. The method:

1. **Incremental Analysis**: Feeds reasoning steps progressively (paragraph-by-paragraph) to the model, capturing intermediate answers after each step
2. **Answer Shift Detection**: Identifies when the answer changes between reasoning steps, indicating potential bias influence
3. **Targeted Arbitration**: When conflicts occur, directly compares the competing answers and their supporting reasoning to make an informed decision
4. **Early Stopping**: Terminates after 3 consecutive identical answers, assuming reasoning has stabilized

**Bias mitigation mechanism**: By monitoring how answers evolve during reasoning, ADBP catches cases where biased assumptions early in the chain lead to incorrect conclusions. The arbitration step forces the model to explicitly justify answer choices without relying on stereotypical shortcuts.

### Method 2: SFRP (Stereotype-Free Reasoning Pattern)

**How it mitigates bias**: Filters out explicitly biased reasoning steps before final answer generation.

SFRP uses an external LLM judge (LLaMA-2-7B) to identify and remove biased content from reasoning chains:

1. **Bias Scoring**: Each reasoning paragraph receives a bias score (0=unbiased, 1-4=increasing bias levels)
2. **Selective Filtering**: Retains only paragraphs scored 0 (completely unbiased), discarding all others
3. **Re-inference**: Generates a new answer using only the filtered, unbiased reasoning
4. **Fallback Strategy**: Uses original answer if no unbiased reasoning remains

**Bias mitigation mechanism**: By reconstructing reasoning chains from only unbiased steps, SFRP prevents stereotypical thinking patterns from influencing final decisions. This forces the model to reach conclusions without relying on biased heuristics.

## How These Methods Complement Each Other

- **ADBP**: Detects *implicit bias* through behavioral signals (answer instability) without requiring explicit bias labels
- **SFRP**: Removes *explicit bias* by filtering reasoning content flagged by an external judge
- **Combined strength**: ADBP catches bias even when it's subtle or embedded in seemingly neutral language; SFRP removes overtly biased statements

## Current Implementation Results

### SFRP Bias Detection Findings
The LLaMA-2-7B judge analysis reveals the extent of bias in the reasoning:
- **95% of examples**: All reasoning steps contain bias (scores ≥2), leaving no unbiased content to work with
- **5% of examples**: Found at least one unbiased paragraph that can be retained for re-inference
- **Score distribution**: Predominantly scores of 2 (mild bias) and 4 (extreme bias)
- **Implication**: The reasoning model's CoT exhibits pervasive bias, making pure filtering approaches challenging

### Performance Characteristics
**ADBP**: ~9 seconds/example on average
- Efficiently processes most examples through early stopping
- Full incremental analysis when reasoning instability detected

**SFRP**: Bimodal performance
- Fast (<1 sec) when all paragraphs filtered → copies original answer
- Slow (20-60 sec) when unbiased reasoning found → full re-inference required

## Reproduction Commands

```bash
# ADBP - Incremental reasoning analysis
python adbp.py adbp_input_equal_equal.jsonl adbp_results_equal_equal.csv \
    deepseek-ai/DeepSeek-R1-Distill-Qwen-14B 0

# SFRP - Bias filtering with pre-computed judge scores
python sfrp_with_precomputed_judge.py adbp_input_equal_equal.jsonl \
    ../evaluation/llm_as_judge_results/Sexualorientation_llama3_8b_deepseek_8b_equal_equal_llama_2_7b_chat_hf_single_eval_original.jsonl \
    sfrp_results_equal_equal_FIXED.csv \
    deepseek-ai/DeepSeek-R1-Distill-Qwen-14B 0
```

## Bias Mitigation Impact

Both methods address bias through different mechanisms:

**ADBP's contribution**: Provides robustness against reasoning instability by validating that conclusions remain consistent regardless of how information is presented. When bias causes answer fluctuations, arbitration forces explicit comparison rather than stereotype-based shortcuts.

**SFRP's contribution**: Creates cleaner reasoning pathways by removing explicitly biased content. Even when most reasoning is filtered (95% of cases), the method reveals the pervasiveness of bias and provides ground truth for which reasoning steps contain problematic content.

**Key insight**: The finding that 95% of reasoning steps contain detectable bias (scores ≥2) demonstrates that bias mitigation cannot rely solely on filtering—it must also address the fundamental reasoning patterns that generate biased content in the first place. This validates the need for complementary approaches like ADBP that work with the model's reasoning process rather than just filtering its output.
