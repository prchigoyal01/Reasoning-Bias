========================================================================
SLURM Job: 35903706 | Array Task: 133
========================================================================
Eval Mode:  reasoning
Model:      deepseek-ai/DeepSeek-R1-Distill-Llama-8B
Language:   en
Category:   Age_control
========================================================================
INFO 11-11 02:56:13 [__init__.py:216] Automatically detected platform cuda.
============================================================
MBBQ EVALUATION
============================================================
Model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
Eval Mode: reasoning
Language: en
Category: Age_control
============================================================

Loading dataset...
Loading reasoning evaluator...
Loading model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
INFO 11-11 02:56:17 [utils.py:233] non-default args: {'trust_remote_code': True, 'dtype': 'float16', 'disable_log_stats': True, 'model': 'deepseek-ai/DeepSeek-R1-Distill-Llama-8B'}
INFO 11-11 02:56:17 [model.py:547] Resolved architecture: LlamaForCausalLM
WARNING 11-11 02:56:17 [model.py:1733] Casting torch.bfloat16 to torch.float16.
INFO 11-11 02:56:17 [model.py:1510] Using max model len 131072
INFO 11-11 02:56:17 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=16384.
[1;36m(EngineCore_DP0 pid=29910)[0;0m INFO 11-11 02:56:18 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=29910)[0;0m INFO 11-11 02:56:18 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Llama-8B, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=29910)[0;0m INFO 11-11 02:56:20 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=29910)[0;0m WARNING 11-11 02:56:20 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=29910)[0;0m INFO 11-11 02:56:20 [gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-R1-Distill-Llama-8B...
[1;36m(EngineCore_DP0 pid=29910)[0;0m INFO 11-11 02:56:20 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=29910)[0;0m INFO 11-11 02:56:20 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=29910)[0;0m INFO 11-11 02:56:21 [weight_utils.py:392] Using model weights format ['*.safetensors']
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 699, in run_engine_core
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     self._init_executor()
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     self.load_weights(model, model_config)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/model_loader/default_loader.py", line 264, in load_weights
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     loaded_weights = model.load_weights(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 615, in load_weights
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return loader.load_weights(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 294, in load_weights
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     autoloaded_weights = set(self._load_module("", self.module, weights))
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 243, in _load_module
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     for child_prefix, child_weights in self._groupby_prefix(weights):
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 132, in _groupby_prefix
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     for prefix, group in itertools.groupby(weights_by_parts,
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 129, in <genexpr>
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     weights_by_parts = ((weight_name.split(".", 1), weight_data)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 291, in <genexpr>
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     weights = ((name, weight) for name, weight in weights
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 615, in <genexpr>
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return loader.load_weights(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/model_loader/default_loader.py", line 246, in get_all_weights
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     yield from self._get_weights_iterator(primary_weights)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/model_loader/default_loader.py", line 160, in _get_weights_iterator
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     hf_folder, hf_weights_files, use_safetensors = self._prepare_weights(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/model_loader/default_loader.py", line 112, in _prepare_weights
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     hf_folder = download_weights_from_hf(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/vllm/model_executor/model_loader/weight_utils.py", line 398, in download_weights_from_hf
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     hf_folder = snapshot_download(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return fn(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 332, in snapshot_download
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     thread_map(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 69, in thread_map
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 51, in _executor_map
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/tqdm/std.py", line 1169, in __iter__
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     for obj in iterable:
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/concurrent/futures/_base.py", line 621, in result_iterator
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     yield _result_or_cancel(fs.pop())
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/concurrent/futures/_base.py", line 319, in _result_or_cancel
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return fut.result(timeout)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return self.__get_result()
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     raise self._exception
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/concurrent/futures/thread.py", line 58, in run
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     result = self.fn(*self.args, **self.kwargs)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 306, in _inner_hf_hub_download
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return hf_hub_download(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return fn(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     return _hf_hub_download_to_cache_dir(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1168, in _hf_hub_download_to_cache_dir
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     _download_to_tmp_and_move(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1720, in _download_to_tmp_and_move
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     xet_get(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]   File "/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 626, in xet_get
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708]     download_files(
[1;36m(EngineCore_DP0 pid=29910)[0;0m ERROR 11-11 04:28:02 [core.py:708] RuntimeError: Data processing error: CAS service error : ReqwestMiddleware Error: couldn't get token: TokenRefreshFailure("Error refreshing token: PyErr { type: <class 'requests.exceptions.ConnectionError'>, value: ConnectionError(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 0bc9262e-77ea-45ae-8c45-ea9a8381a48b)'), traceback: Some(\"Traceback (most recent call last):\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/file_download.py\\\", line 594, in token_refresher\\n    connection_info = refresh_xet_connection_info(file_data=xet_file_data, headers=headers)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\\\", line 114, in _inner_fn\\n    return fn(*args, **kwargs)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/utils/_xet.py\\\", line 116, in refresh_xet_connection_info\\n    return _fetch_xet_connection_info_with_url(file_data.refresh_route, headers)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\\\", line 114, in _inner_fn\\n    return fn(*args, **kwargs)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/utils/_xet.py\\\", line 186, in _fetch_xet_connection_info_with_url\\n    resp = get_session().get(headers=headers, url=url, params=params)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/requests/sessions.py\\\", line 602, in get\\n    return self.request(\\\"GET\\\", url, **kwargs)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/requests/sessions.py\\\", line 589, in request\\n    resp = self.send(prep, **send_kwargs)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/requests/sessions.py\\\", line 703, in send\\n    r = adapter.send(request, **kwargs)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py\\\", line 95, in send\\n    return super().send(request, *args, **kwargs)\\n  File \\\"/ocean/projects/cis250182p/pgoyal2/conda_envs/MBBQEnv/lib/python3.10/site-packages/requests/adapters.py\\\", line 659, in send\\n    raise ConnectionError(err, request=request)\\n\") }")
âœ— FAILED (exit code: 1)
========================================================================
